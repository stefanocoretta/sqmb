---
title: "Statistics and Quantitative Methods (S2)"
subtitle: "Week 8 - Multiple predictors and interactions"
author: "Elizabeth Pankratz"
institute: "University of Edinburgh"
date: "2023/03/07"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css:
      - ../xaringan-themer.css
      - ../custom.css
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
      beforeInit: "../macros.js"
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(
  fig.width=7, fig.height=5, fig.retina=3,
  out.width = "60%", fig.align = "center",
  cache = FALSE,
  echo = FALSE,
  message = FALSE, 
  warning = FALSE,
  hiline = TRUE
)
knitr::opts_knit$set(root.dir = here::here())

library(xaringanExtra)
use_xaringan_extra(c("panelset", "tachyons", "freezeframe"))

library(tidyverse)
theme_set(theme_light())
library(brms)
library(extraDistr)
library(ggdist)
library(glue)

theme_update(text = element_text(size=16))

options(ggplot2.discrete.fill = RColorBrewer::brewer.pal(8, "Dark2"))
options(ggplot2.discrete.colour = RColorBrewer::brewer.pal(8, "Dark2"))
options(show.signif.stars = FALSE)
my_seed <- 8878
```

```{r read-data}
shallow <- read_csv("data/shallow.csv") %>%
  filter(
    Group == "L1",
    Critical_Filler == "Critical",
    RT > 0
  ) %>%
  mutate(
    Accuracy = ifelse(ACC == 1, "correct", "incorrect")
  )
```


class: center middle reverse

# Please fill out today's attendance form:

`https://forms.office.com/e/A0X816LnUp`

![:scale 30%](imgs/qr.png)

<!-- .bg-washed-green.b--dark-green.ba.bw2.br3.shadow-5.ph4.mt2[ -->
<!-- We will focus on **accuracy** (correct identification of real word: **correct/incorrect**) for L1 participants. ]-->

---
layout: false
layout: true

## Summary from last time

---

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
**(1)** What are **binary outcomes?**

- Outcomes with two discrete levels (e.g., yes/no, grammatical/ungrammatical, correct/incorrect).
]


.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
**(2)** How do we **visualise** them?

- As proportions.
]


.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
**(3)** What **distribution** do binary outcomes follow?

- A Bernoulli distribution with one parameter, $p$, the probability of success.
- In brms: `family = bernoulli()`.
]

---

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
**(4)**  How do we fit a model requiring a **continuous outcome space** using binary data?

- We model the binary outcomes as being generated based on the probability of success $p$.
- We transform this probability into log-odds, which is continuous.
]


.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
**(5)** How do we **interpret** the estimates of such a model?

- The model's estimates are in log-odds space.
- To interpret them, we convert back to probability space using `plogis()`.
]


.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
**(6)** What are **credible intervals**?

- Credible intervals are the difference between two quantiles.
- For Bayesian modelling, they are the region in which, with some probability (usually 95%), the true value lies.
]

---
layout:false

## Five learning objectives for today

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
**(1)** What is a **factorial design?**
]

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
**(2)** How do we estimate and interpret the effects of **multiple predictors?**
]

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
**(3)** How do we deal with situations when **one predictor's effect is different, depending on the value of the other predictor?**
]

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
**(4)** How can such interactions between predictors be **built into our models?**
]

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
**(5)** How do we **interpret model estimates** of interactions? 
]

---

## What is a factorial design?

- TODO: tree of one factor with two levels, A
- TODO: then another one, B

<br>

|    	    | B = B1     	| B = B2     	|
|-------- |--------	|--------	|
| **A = A1** 	| A1, B1 	| A1, B2 	|
| **A = A2** 	| A2, B1 	| A2, B2 	|
  
<br>

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
How can we analyse **both predictors** at the same time?
]

---
layout:false
layout: true

## Running example: Morphological processing
---

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
- **Lexical decision task:** Is the string you see a word in English or not?
  - Outcome variable: **Accuracy (incorrect/correct)**.
]

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
- Last week: **Relation_type**.
- This week: **Relation_type (Unrelated/Constituent)**  and **Branching (Left/Right)**.
]

(TODO: make graphic showing the two poss syntax trees)


|                                 	| Branching = Left  	| Branching = Right  	|
|---------------------------------	|-------------------	|--------------------	|
| **Relation_type = Unrelated**   	| Unrelated, Left   	| Unrelated, Right   	|
| **Relation_type = Constituent** 	| Constituent, Left 	| Constituent, Right 	|

---

```{r setup-shallow, echo = TRUE}
shallow <- shallow %>% 
  filter(Relation_type != 'NonConstituent') %>% 
  mutate(
    Relation_type = factor(Relation_type, levels = c('Unrelated', 'Constituent')),
    Branching     = factor(Branching, levels = c('Left', 'Right')),
    Accuracy      = factor(Accuracy, levels = c('incorrect', 'correct'))
  )
```

---
layout:false

## Visualising `Relation_type` and `Branching`

```{r shallow-barplot}
# Manual recreation of proportions stacked bar chart (as basis for later)
(barplot_shallow <- shallow %>% 
  group_by(Relation_type, Branching) %>%
  summarise(correct = mean(ACC)) %>% 
  mutate(incorrect = 1 - correct) %>% 
  pivot_longer(correct:incorrect, names_to = 'Accuracy', values_to = 'propn') %>% 
  mutate(Accuracy = factor(Accuracy, levels = c('incorrect', 'correct'))) %>% 
  # gg the plot
  ggplot(aes(x = Relation_type, y = propn)) +
  geom_bar(stat = 'identity', aes(fill = Accuracy)) +
  facet_wrap(~ Branching, labeller = labeller(Branching = label_both)) +
  labs(y = 'Proportion',
       x = 'Relation type'))
```


---

## We've seen multiple predictors before!

<br> <br> <br> <br> <br> <br> <br>

$$logit(p) = \beta_0 + \beta_1 \cdot relation_{ncons} + \beta_2 \cdot relation_{cons}$$

---
layout:false
layout:true

## Setting up `Relation_type` and `Branching`

---

<br>

|                                 	| Branching = Left  	| Branching = Right  	|
|---------------------------------	|-------------------	|--------------------	|
| **Relation_type = Unrelated**   	| Unrelated, Left   	| Unrelated, Right   	|
| **Relation_type = Constituent** 	| Constituent, Left 	| Constituent, Right 	|

<br>

| Relation_type 	| Branching 	|
|---------------	|-----------	|
| Unrelated     	| Left      	|
| Unrelated     	| Right     	|
| Constituent   	| Left      	|
| Constituent   	| Right     	|

---

<br>

<!-- my condolences to anyone trying to read this -->

| When: | Then coded as: |
| --- | --- |
| <table> <thead> <tr> <th>Relation_type</th> <th>Branching</th> </tr> </thead> <tbody> <tr> <td>Unrelated</td> <td>Left</td> </tr> <tr> <td>Unrelated</td> <td>Right</td> </tr> <tr> <td>Constituent</td> <td>Left</td> </tr> <tr> <td>Constituent</td> <td>Right</td> </tr> </tbody> </table> | <table> <thead> <tr> <th>Relation_type</th> <th>Branching</th> </tr> </thead> <tbody> <tr> <td>0</td> <td>0</td> </tr> <tr> <td>0</td> <td>1</td> </tr> <tr> <td>1</td> <td>0</td> </tr> <tr> <td>1</td> <td>1</td> </tr> </tbody> </table> |  
<!-- | Relation_type 	| Branching 	| -->
<!-- |---------------	|-----------	| -->
<!-- | Unrelated     	| Left      	| -->
<!-- | Unrelated     	| Right     	| -->
<!-- | Constituent   	| Left      	| -->
<!-- | Constituent   	| Right     	| -->

<!-- | Relation_type 	| Branching 	| -->
<!-- |---------------	|-----------	| -->
<!-- | 0             	| 0         	| -->
<!-- | 0             	| 1         	| -->
<!-- | 1             	| 0         	| -->
<!-- | 1             	| 1         	| -->

---
layout: false

## What will the $\beta$s mean now?

| When: | Then coded as: |
| --- | --- |
| <table> <thead> <tr> <th>Relation_type</th> <th>Branching</th> </tr> </thead> <tbody> <tr> <td>Unrelated</td> <td>Left</td> </tr> <tr> <td>Unrelated</td> <td>Right</td> </tr> <tr> <td>Constituent</td> <td>Left</td> </tr> <tr> <td>Constituent</td> <td>Right</td> </tr> </tbody> </table> | <table> <thead> <tr> <th>Relation_type</th> <th>Branching</th> </tr> </thead> <tbody> <tr> <td>0</td> <td>0</td> </tr> <tr> <td>0</td> <td>1</td> </tr> <tr> <td>1</td> <td>0</td> </tr> <tr> <td>1</td> <td>1</td> </tr> </tbody> </table> | 
<br>

$$logit(p) = \beta_0 + (\beta_1 \cdot relation) + (\beta_2 \cdot branch)$$
<br>

$$
\begin{aligned}
\text{Unrelated, Left:}     & & \beta_0 &+ (\beta_1 \cdot 0) + (\beta_2 \cdot 0)  &&= \beta_0  &\\
\text{Unrelated, Right:}    & & \beta_0 &+ (\beta_1 \cdot 0) + (\beta_2 \cdot 1)  &&= \beta_0 + \beta_2 &\\
\text{Constituent, Left:}   & & \beta_0 &+ (\beta_1 \cdot 1) + (\beta_2 \cdot 0)  &&= \beta_0 + \beta_1 &\\
\text{Constituent, Right:}  & & \beta_0 &+ (\beta_1 \cdot 1) + (\beta_2 \cdot 1)  &&= \beta_0 + \beta_1 + \beta_2 &\\
\end{aligned}
$$

---

## Let's fit a model

- show model fit code and fixef summary

---

## Model estimates: `Intercept`

- including plogis()

---

## Model estimates: `Relation_type`


---

## Model estimates: `Branching`


---

## Conditional posterior probabilities

- density plot
- TODO: overlay the dots and error bars so we know what we're looking at in the next plot

---

## Do these estimates match the data?

- Show shallow barplot again
- Then overlay means + error bars of model estimate
- no bueno: effects too big / too small

---
class: center middle reverse

# Time for a wee break!

### If you haven't yet, please fill in today's attendance form:

`https://forms.office.com/e/A0X816LnUp`

![:scale 30%](imgs/qr.png)

---

## How does the current model fall short?

- The question we want to answer: "Is the effect of relation type different when `Branching == Left` than when `Branching == Right`?"
- Our model currently doesn't let effects differ between levels of other variables

- The solution: Interaction.

---

## In other words: we want to get at a _difference of differences_

- Show shallow barplot again, this time with vertical brackets between the two levels to illustrate diffs

---

## How?

- Create a new variable that represents the interaction
- Give it its own beta
- Estimate the beta to get a sense of the differences

---

## Treatment coding matrix, now with more interaction

| When: | Then coded as: |
| --- | --- |
| <table> <thead> <tr> <th>Relation_type</th> <th>Branching</th> </tr> </thead> <tbody> <tr> <td>Unrelated</td> <td>Left</td> </tr> <tr> <td>Unrelated</td> <td>Right</td> </tr> <tr> <td>Constituent</td> <td>Left</td> </tr> <tr> <td>Constituent</td> <td>Right</td> </tr> </tbody> </table> | <table> <thead> <tr> <th>Relation_type</th> <th>Branching</th> <th>Relation_type:Branching</th> </tr> </thead> <tbody> <tr> <td>0</td> <td>0</td> <td>0 \* 0 = 0</td> </tr> <tr> <td>0</td> <td>1</td> <td>0 \* 1 = 0</td> </tr> <tr> <td>1</td> <td>0</td> <td>1 \* 0 = 0</td> </tr> <tr> <td>1</td> <td>1</td> <td>1 \* 1 = 0</td> </tr> </tbody> </table>  |  

<br>

$$logit(p) = \beta_0 + (\beta_1 \cdot relation) + (\beta_2 \cdot branch) + (\beta_3 \cdot relation:branch)$$

<br>

$$
\begin{aligned}
\text{Unrelated, Left:}     && \beta_0 &+ (\beta_1 \cdot 0) + (\beta_2 \cdot 0) + (\beta_3 \cdot 0) &&= \beta_0  &\\
\text{Unrelated, Right:}    && \beta_0 &+ (\beta_1 \cdot 0) + (\beta_2 \cdot 1) + (\beta_3 \cdot 0) &&= \beta_0 + \beta_2 &\\
\text{Constituent, Left:}   && \beta_0 &+ (\beta_1 \cdot 1) + (\beta_2 \cdot 0) + (\beta_3 \cdot 0) &&= \beta_0 + \beta_1 &\\
\text{Constituent, Right:}  && \beta_0 &+ (\beta_1 \cdot 1) + (\beta_2 \cdot 1) + (\beta_3 \cdot 1) &&= \beta_0 + \beta_1 + \beta_2 + \beta_3 &\\
\end{aligned}
$$

---

## What does the extra $\beta$ give us?

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
When both variables are coded as 1 (non-baseline) in a model **with no interaction:**

$$
 \beta_0 + (\beta_1 \cdot 1) + (\beta_2 \cdot 1) = \beta_0 + \beta_1 + \beta_2 \\
$$
]

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
And in a model **with an interaction:**

$$
\beta_0 + (\beta_1 \cdot 1) + (\beta_2 \cdot 1) + (\beta_3 \cdot 1) = \beta_0 + \beta_1 + \beta_2 + \beta_3 \\
$$
]

.bg-washed-green.b--dark-green.ba.bw2.br3.shadow-5.ph4.mt2[
$\beta_3$ can **modulate** the other effects $\beta_1$ and $\beta_2$.
]

---

## Fitting a model with an interaction

- add that one might also see the `*` syntax


---

## Model estimates: `Intercept`

- including plogis()

---

## Model estimates: `Relation_type`


---

## Model estimates: `Branching`


---

## Model estimates: `Relation_type:Branching`

---

## Conditional posterior probabilities

- density plot
- TODO: overlay the dots and error bars so we know what we're looking at in the next plot

---

## Do these new estimates match the data?

- Show shallow barplot again
- Then overlay means + error bars of model estimate
- better!!!

---

## No interaction vs. with interaction

- show both barplots with model estims side by side, look at difference


---
layout: false
layout: true

## Learning objectives revisited

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
**(1)** What is a **factorial design?**
]

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
**(2)** How do we estimate and interpret the effects of **multiple predictors?**
]

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
**(3)** How do we deal with situations when **one predictor's effect is different, depending on the value of the other predictor?**
]

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
**(4)** How can such interactions between predictors be **built into our models?**
]

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
**(5)** How do we **interpret model estimates** of interactions? 
- Carefully!
]

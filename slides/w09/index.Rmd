---
title: "Statistics and Quantitative Methods (S2)"
subtitle: "Week 9 - Continuous predictors"
author: "Elizabeth Pankratz"
institute: "University of Edinburgh"
date: "2023/03/21"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css:
      - ../xaringan-themer.css
      - ../custom.css
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
      beforeInit: "../macros.js"
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(
  fig.width=7, fig.height=5, fig.retina=3,
  out.width = "60%", fig.align = "center",
  cache = FALSE,
  echo = FALSE,
  message = FALSE, 
  warning = FALSE,
  hiline = TRUE
)
knitr::opts_knit$set(root.dir = here::here())

library(xaringanExtra)
use_xaringan_extra(c("panelset", "tachyons", "freezeframe"))

library(tidyverse)
theme_set(theme_light())
library(brms)
library(extraDistr)
library(ggdist)
library(glue)
library(posterior)

theme_update(text = element_text(size=14))

options(ggplot2.discrete.fill = RColorBrewer::brewer.pal(8, "Dark2"))
options(ggplot2.discrete.colour = RColorBrewer::brewer.pal(8, "Dark2"))
options(show.signif.stars = FALSE)
my_seed <- 8878

build <- function(){
  rmarkdown::render('slides/w09/index.Rmd')
}
```

class: center middle reverse

# Please fill out today's attendance form:

<!-- `https://forms.office.com/e/A0X816LnUp` -->

<!-- ![:scale 30%](imgs/qr.png) -->

<!-- .bg-washed-green.b--dark-green.ba.bw2.br3.shadow-5.ph4.mt2[ -->
<!-- We will focus on **accuracy** (correct identification of real word: **correct/incorrect**) for L1 participants. ]-->

---
layout: false
layout: true

## Summary from last time

---

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
**(1)** What is a **factorial design?**
- A design with multiple predictors in which data is gathered for **every combination** of those predictors' levels.
]

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
**(2)** How do we estimate and interpret the effects of **multiple predictors?**
- A predictor's $\beta$ is the effect of that predictor *when the other predictor's value is 0*.
]

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
**(3)** How do we deal with situations when **one predictor's effect is different, depending on the value of the other predictor?**
- We fit a model that contains an **interaction term** between those two predictors.
]

---

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
**(4)** How can such interactions between predictors be **built into our models?**
- The interaction term is defined as the **product** of the two interacting predictors.
- It gets its own $\beta$ coefficient, which we estimate as usual.
]

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
**(5)** How do we **interpret model estimates** of interactions? 
- The interaction term's $\beta$ tells us **how much one predictor's effect changes between the baseline and non-baseline levels of the other**.
- Interactions are symmetrical, and so they have two equivalent interpretations.
]

---
layout:false

## Three learning objectives for today

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
**(1)** How do we model variables that aren't categorical, but continuous?
]

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
**(2)** How do we interpret model estimates for continuous predictors?
]

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
**(3)** How do we fit and interpret interactions involving continuous predictors?
]

---

## Up to now: Categorical predictors, numerically coded

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[

Categorical predictors from earlier in the course:

- `Modality`, with levels `Taste` / `Smell`

- `Relation_type`, with levels `Unrelated` / `Constituent` / `NonConstituent`

- `Branching`, with levels `Left` / `Right`

]

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[

To make these predictors modellable, we treatment-coded them using 0s and 1s.

]

.bg-washed-green.b--dark-green.ba.bw2.br3.shadow-5.ph4.mt2[

Good news: Continuous variables are already numeric!

]

???

But, consequence: interpreting the model's estimates is a little different.

---
layout: true

## How to interpret estimates from a continuous predictor?

---

--

### A little excursion into math from school...

--

<!-- Our linear expressions so far: -->

<!-- .f3[ -->
<!-- $$ y = \beta_0 + \beta_1 \cdot x  $$] -->

The basic equation for a line:

.f3[
$$
y = c + m\cdot x
$$
]

where

$$
\begin{aligned}
y: &~~~ \text{outcome variable} \\
c: &~~~ \text{intercept} \\
m: &~~~ \text{slope} \\
x: &~~~ \text{input variable} \\
\end{aligned}
$$
<br>

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
Let's see an example: $y = 4 + 2x$.
]


---

<!-- TODO: overlays! intercept > change in x > change in y -->

```{r line-pos-slope}
palette <- RColorBrewer::brewer.pal(8, "Dark2")

tibble(
  x = 0:3,
  y = 2*x + 4
) %>% 
  ggplot(aes(x=x, y=y, group=1)) +
  geom_line(linewidth = 1.5) +
  theme(panel.grid.minor.x = element_blank()) +
  # one unit in x ("run")
  geom_segment(x = 1, xend = 2, y = 6, yend = 6, colour = palette[3],
               arrow = arrow(length = unit(0.3,"cm")),
               linewidth = 1) +
  geom_text(x = 1, y = 5.65,
            label = 'For a change of 1 in x...',
            colour = palette[3],
            hjust = 0,
            size = 5) +
  # corresp change in y ("rise")
  geom_segment(x = 2, xend = 2, y = 6, yend = 7.95, colour = palette[2],
               arrow = arrow(length = unit(0.3,"cm")),
               linewidth = 1) +
  geom_text(x = 2.05, y = 7, 
            label = '... the slope of the line\n is the change in y.',
            colour = palette[2],
            hjust = 0,
            size = 5) +
  # intercept (should sound familiar)
  geom_text(x = 0.1, y = 4,
            label = 'The y-intercept is the value of y when x = 0.',
            colour = palette[1],
            hjust = 0,
            size = 5) +
  geom_point(x = 0, y = 4,
             colour = palette[1],
             size = 5) +
  labs(
    title = 'y = 4 + 2x'
  ) +
  NULL
```

---

<!-- TODO: overlays! intercept > change in x > change in y -->

```{r line-neg-slope}
tibble(
  x = 0:3,
  y = -2*x + 4
) %>% 
  ggplot(aes(x=x, y=y, group=1)) +
  geom_line(size = 1.5) +
  theme(panel.grid.minor.x = element_blank()) +
  # one unit in x ("run")
  geom_segment(x = 1, xend = 2, y = 2, yend = 2, colour = palette[3],
               arrow = arrow(length = unit(0.3,"cm")),
               size = 1) +
  geom_text(x = 1, y = 2.4, 
            label = 'For a change of 1 in x...', 
            colour = palette[3],
            hjust = 0,
            size = 5) +
  # corresp change in y ("rise")
  geom_segment(x = 2, xend = 2, y = 2, yend = 0.05, colour = palette[2],
               size = 1,
               arrow = arrow(length = unit(0.3,"cm"))
               ) +
  geom_text(x = 2.05, y = 1, 
            label = '... a negative slope\nmeans y decreases.', 
            colour = palette[2],
            hjust = 0,
            size = 5) +
  # intercept (should sound familiar)
  geom_text(x = 0.1, y = 4,
            label = 'The y-intercept is the value of y when x = 0.',
            colour = palette[1],
            hjust = 0,
            size = 5) +
  geom_point(x = 0, y = 4,
             colour = palette[1],
             size = 5) +
  labs(
    title = 'y = 4 + â€“2x'
  ) +
  NULL
```


---
layout:false

## So what?
.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[

Our linear models have the same form as the lines we saw in school.

$$
\begin{aligned}
y ~ &=& b ~~ &+& m &\cdot x \\ 
outcome ~ &=& intercept ~~ &+& slope &\cdot predictor \\
outcome ~ &=& \beta_0 ~~ &+& \beta_1 &\cdot predictor \\
\end{aligned}
$$
]

.bg-washed-green.b--dark-green.ba.bw2.br3.shadow-5.ph4.mt2[

$\beta_0$ corresponds to the line's $y$-intercept:

**The outcome value when the input value (i.e., the predictor) equals zero.**

]

.bg-washed-green.b--dark-green.ba.bw2.br3.shadow-5.ph4.mt2[

And for continuous variables, $\beta_1$ has the same interpretation as $b$:

**The change in the outcome that results from a change of 1 (a.k.a., one unit change)<br> in the predictor.**

]

---

## Interpreting model estimates: A comparison

.pull-left[
.center[
.f4[
**0/1 treatment-coded predictors**
]
]
]

.pull-right[
.center[
.f4[
**Continuous predictors**
]
]
]

--

.pull-left[
.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
**Intercept ( $\beta_0$ ):**

- Estimated value of the outcome when predictor(s) equal to zero. 
  - i.e., **at predictor's baseline/reference level**.
]
]

.pull-right[
.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
**Intercept ( $\beta_0$ ):**

- Estimated value of the outcome when predictor(s) equal to zero. 
  - **on the predictor's scale**, e.g., <br> 0 ms, 0 lbs, 0 metres.
  <!-- - or if centered: 0 = the predictor's mean -->
]
]

--

.pull-left[
.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
**Effects (other $\beta$s):**

- Difference between estimated value of the outcome when predictor = 0 and when predictor = 1.
]
]

.pull-right[
.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
**Effects (other $\beta$s):**

- Difference between estimated value of the outcome **for one unit increase in predictor's value**.
]
]

---

## Let's build a model!

```{r read-data}
dur_ita_pol <- read_csv('data/dur-ita-pol.csv') %>% 
  mutate(
    log_v1_dur = log(v1_duration)
  )
```


--

.pull-left[

```{r dens-dur, out.width = "100%", fig.height = 6}
dur_ita_pol %>% 
  ggplot(aes(x= log_v1_dur)) +
  geom_density(fill = 'grey', alpha = 0.5) +
  geom_rug() +
  labs(x = 'Vowel duration (log ms)',
       title = 'Outcome: Log vowel duration')
```

]

.pull-right[

```{r dens-sr, out.width = "100%", fig.height = 6}
dur_ita_pol %>% 
  ggplot(aes(x= speech_rate)) +
  geom_density(fill = 'grey', alpha = 0.5) +
  geom_rug() +
  labs(x = 'Speech rate (syllables/sec)',
       title = 'Predictor: Speech rate')
```

]


.f6[
(Data from `dur-ita-pol.csv`.)
]

---

## Log vowel duration ~ Speech rate

```{r scatter-dur-sr}
(p_dur_sr <- dur_ita_pol %>% 
   ggplot(aes(x = speech_rate, y = log_v1_dur)) +
   geom_point() +
   labs(
     x = 'Speech rate (syllables/sec)',
     y = 'Vowel duration (log ms)'
   ) +
   NULL)
```

???

Makes sense.
The faster you talk, the shorter your vowels are gonna be.

---

## The model we'll fit

.f3[
$$
\begin{aligned}
log(duration) &\sim Gaussian(\mu, \sigma)\\
\mu &= \beta_0 + \beta_1 \cdot speechrate \\
\beta_0 &\sim Gaussian(\mu_0, \sigma_0)\\
\beta_1 &\sim Gaussian(\mu_1, \sigma_1)\\
\sigma &\sim TruncGaussian(\mu_2, \sigma_2)
\end{aligned}
$$
]

---

```{r fit1, echo = TRUE}
dur_sr_bm <- brm(
  log_v1_dur ~ speech_rate,
  family = gaussian(),
  data = dur_ita_pol,
  backend = 'cmdstanr',
  file = 'data/cache/dur_sr_bm'
)
```


--

```{r fit1-summ, echo = TRUE}
summary(dur_sr_bm)
```



---

## Interpreting $\beta_0$ and $\beta_1$

```{r fit1-summ2}
cat(capture.output(summary(dur_sr_bm))[8:12], sep = "\n")
```

<br>

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[

**`Intercept`, a.k.a. $\beta_0$:**

- The mean log vowel duration when speech rate is equal to 0 is 5.88 (95% CrI: [5.78, 5.99]).

**`speech_rate`, a.k.a. $\beta_1$:**

- For one unit change in speech rate, log vowel duration changes by â€“0.24 (95% CrI: [â€“0.26, â€“0.22]).

]


.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[

**But ... what's a speech rate of zero?**

]

---

## To interpret the intercept more sensibly:<br> Centre `speech_rate`

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[

To centre a variable means to **transform it so that the mean of the centered version is zero.**
]

--

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[

How?
]

--

.bg-washed-green.b--dark-green.ba.bw2.br3.shadow-5.ph4.mt2[

**Subtract the variable's mean from every observation:**
]

```{r centre, echo = TRUE}
dur_ita_pol <- dur_ita_pol %>% 
  mutate(
    speech_rate_c = speech_rate - mean(speech_rate)
  )
```

---

## How does the centered version compare to the original?

.pull-left[

```{r scatter-dur-sr-2, out.width = "100%"}
p_dur_sr +
  labs(title = 'Speech rate is not centered')
```

```{r mean-noncentered, echo = TRUE}
round(mean(dur_ita_pol$speech_rate), 2)
```

]

.pull-right[

```{r scatter-dur-sr-3, out.width = "100%"}
dur_ita_pol %>% 
   ggplot(aes(x = speech_rate_c, y = log_v1_dur)) +
   geom_point() +
   labs(
     x = 'Centered speech rate (syllables/sec)',
     y = 'Vowel duration (log ms)',
     title = 'Speech rate is centered'
   ) +
   NULL
```

```{r mean-centered, echo = TRUE}
round(mean(dur_ita_pol$speech_rate_c))
```

]

???

So we predict we'll see the same slope estimate.
But a different intercdept estimate, since now the place where the line intersects with x = 0 is different.

---

```{r fit2, echo = TRUE}
dur_sr_c_bm <- brm(
  log_v1_dur ~ speech_rate_c,
  family = gaussian(),
  data = dur_ita_pol,
  backend = 'cmdstanr',
  file = 'data/cache/dur_sr_c_bm'
)
```

--

```{r fit2-summ, echo = TRUE}
summary(dur_sr_c_bm)
```

---



## Interpreting the new $\beta_0$ and $\beta_1$

```{r fit2-summ2}
cat(capture.output(summary(dur_sr_c_bm))[8:12], sep = "\n")
```

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[

**`Intercept`, a.k.a. $\beta_0$:**

- The mean log vowel duration when centered speech rate is equal to 0, <br>**i.e., when speech rate is at its mean value (which, thanks to the centering, is zero)**,<br> is 4.59 (95% CrI: [4.58, 4.61]).

  - Before, uncentered: $\beta_0$ = 5.88 (95% CrI: [5.78, 5.99]).

**`speech_rate_c`, a.k.a. $\beta_1$, is the same as before:**

- For one unit change in speech rate, log vowel duration changes by â€“0.24 (95% CrI: [â€“0.26, â€“0.22]).

]

--

.bg-washed-green.b--dark-green.ba.bw2.br3.shadow-5.ph4.mt2[

The take-away from Part 1: **Centering continuous variables is pretty much always a good idea.**

]

???

Not going to show mathematical formulation of model with priors filled inâ€”people can figure that out themselves. 

Also not going to do the conditional posterior probability distribs, for reasons of time.
Perhaps in Part 2, prob gotta in the tutorial.

---
class: center middle reverse

# Part 2: Interactions <br> involving a continuous predictor

---
## Speech rate * Italian vowels "a" and "o" 

```{r dur-ita}
dur_ita <- dur_ita_pol %>% 
  filter(
    language == 'Italian',
    vowel %in% c('a', 'o')
  )
```

.pull-left[

```{r dur-ita-public, echo = TRUE, eval = FALSE}
# Subset the data
dur_ita <- dur_ita_pol %>% 
  filter(
    language == 'Italian',
    vowel %in% c('a', 'o')
  )

# Create this plot --->
dur_ita %>% 
  ggplot(aes(x = speech_rate_c, 
             y = log_v1_dur, 
             colour = vowel, 
             fill = vowel)) +
  geom_point() +
  geom_smooth(method = 'lm') +
  labs(
    x = 'Centered speech rate (syll/sec)',
    y = 'Vowel duration (log ms)'
  )
```
]

.pull-right[
```{r dur-ita-plot, out.width = "100%", fig.height = 6}
dur_ita %>% 
  ggplot(aes(x = speech_rate_c, y = log_v1_dur, colour = vowel, fill = vowel)) +
  geom_point() +
  geom_smooth(method = 'lm') +
  labs(
    x = 'Centered speech rate (syll/sec)',
    y = 'Vowel duration (log ms)'
  )
```
]

---

fit the model

---

interpret results

---

Two interpretations of the interaction's beta: 

- `Intercept` a.k.a. $\beta_0$: mean log vowel duration when speech_rate_c is at its mean of 0 and when vowel == 'a' (baseline).
- `speech_rate_c` a.k.a. $\beta_1$: change in the mean log vowel duration when increasing one unit of `speech_rate_c` (e.g., when going from 0 to 1), with vowel == 'a'.
- `vowel0`, a.k.a., $\beta_2$: change in the mean log vowel duration when moving from vowel == 'a' to vowel == 'o' (with speech rate at its mean of zero).
- `speech_rate_c:vowelo` a.k.a. $\beta_3$: a positive coefficient, meaning:
  - 1) there is a positive adjustment to the effect of speech_rate_c when we move from vowel == 'a' (baseline) to vowel == 'o' (non-baseline). 
    - because the effect of `speech_rate_c` is negative, a positive adjustment means that the effect is weaker (brings it closer to zero). 
    - we can see this in the plot: the slope of vowel == 'a' is more strongly negative than the slope of vowel == 'o'.
  - 2) there is a positive adjustment to the effect of moving from vowel == 'a' to vowel == 'o' when we increase one unit of `speech_rate_c`.
    - because the effect of `vowel` is negative, a positive adjustment means that the effect is weaker (brings it closer to zero).
    - we can see this in the plot: the difference between vowel == 'a' and vowel == 'o' gets smaller as we move from L to R on x axis of speech rate.

---

reprise of the treatment coding algebra, now with continuous predictor

---

## Learning objectives revisited

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
**(1)** How do we model variables that aren't categorical, but continuous?
]

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
**(2)** How do we interpret model estimates for continuous predictors?
]

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
**(3)** How do we fit and interpret interactions involving continuous predictors?
]

---
class: center middle reverse

# The Grand Vision



